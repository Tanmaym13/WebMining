{"cells":[{"cell_type":"markdown","metadata":{"id":"uZn0fFfgdV9D"},"source":["# **Question 1 and 2** "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"tRZKVfqbYZao"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","sample_data/doc/doc1.txt\n","sample_data/doc/doc4.txt\n","sample_data/doc/doc5.txt\n","sample_data/doc/doc3.txt\n","sample_data/doc/doc2.txt\n"]}],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer, PorterStemmer\n","from nltk.tokenize import sent_tokenize , word_tokenize\n","import glob\n","import re\n","import os\n","import numpy as np\n","import sys\n","import nltk\n","nltk.download('stopwords')\n","Stopwords = set(stopwords.words('english'))\n","all_words = []\n","dict_global = {}\n","file_folder = 'sample_data/doc/*'\n","idx = 1\n","files_with_index = {}\n","for file in glob.glob(file_folder):\n","    print(file)\n","    fname = file\n","    file = open(file , \"r\")\n","    text = file.read()\n","    text = remove_special_characters(text)\n","    text = re.sub(re.compile('\\d'),'',text)\n","    sentences = sent_tokenize(text)\n","    words = word_tokenize(text)\n","    words = [word for word in words if len(words)\u003e1]\n","    words = [word.lower() for word in words]\n","    words = [word for word in words if word not in Stopwords]\n","    dict_global.update(finding_all_unique_words_and_freq(words))\n","    files_with_index[idx] = os.path.basename(fname)\n","    idx = idx + 1\n","    \n","unique_words_all = set(dict_global.keys())\n","def finding_all_unique_words_and_freq(words):\n","    words_unique = []\n","    word_freq = {}\n","    for word in words:\n","        if word not in words_unique:\n","            words_unique.append(word)\n","    for word in words_unique:\n","        word_freq[word] = words.count(word)\n","    return word_freq\n","def finding_freq_of_word_in_doc(word,words):\n","    freq = words.count(word)\n","        \n","def remove_special_characters(text):\n","    regex = re.compile('[^a-zA-Z0-9\\s]')\n","    text_returned = re.sub(regex,'',text)\n","    return text_returned\n","class Node:\n","    def __init__(self ,docId, freq = None):\n","        self.freq = freq\n","        self.doc = docId\n","        self.nextval = None\n","    \n","class SlinkedList:\n","    def __init__(self ,head = None):\n","        self.head = head\n","linked_list_data = {}\n","for word in unique_words_all:\n","    linked_list_data[word] = SlinkedList()\n","    linked_list_data[word].head = Node(1,Node)\n","word_freq_in_doc = {}\n","idx = 1\n","for file in glob.glob(file_folder):\n","    file = open(file, \"r\")\n","    text = file.read()\n","    text = remove_special_characters(text)\n","    text = re.sub(re.compile('\\d'),'',text)\n","    sentences = sent_tokenize(text)\n","    words = word_tokenize(text)\n","    words = [word for word in words if len(words)\u003e1]\n","    words = [word.lower() for word in words]\n","    words = [word for word in words if word not in Stopwords]\n","    word_freq_in_doc = finding_all_unique_words_and_freq(words)\n","    for word in word_freq_in_doc.keys():\n","        linked_list = linked_list_data[word].head\n","        while linked_list.nextval is not None:\n","            linked_list = linked_list.nextval\n","        linked_list.nextval = Node(idx ,word_freq_in_doc[word])\n","    idx = idx + 1\n","query = input('Enter your query:')\n","query = word_tokenize(query)\n","connecting_words = []\n","cnt = 1\n","different_words = []\n","for word in query:\n","    if word.lower() != \"and\" and word.lower() != \"or\" and word.lower() != \"not\":\n","        different_words.append(word.lower())\n","    else:\n","        connecting_words.append(word.lower())\n","print(connecting_words)\n","total_files = len(files_with_index)\n","zeroes_and_ones = []\n","zeroes_and_ones_of_all_words = []\n","for word in (different_words):\n","    if word.lower() in unique_words_all:\n","        zeroes_and_ones = [0] * total_files\n","        linkedlist = linked_list_data[word].head\n","        print(word)\n","        while linkedlist.nextval is not None:\n","            zeroes_and_ones[linkedlist.nextval.doc - 1] = 1\n","            linkedlist = linkedlist.nextval\n","        zeroes_and_ones_of_all_words.append(zeroes_and_ones)\n","    else:\n","        print(word,\" not found\")\n","        sys.exit()\n","print(zeroes_and_ones_of_all_words)\n","\n","for word in connecting_words:\n","    word_list1 = zeroes_and_ones_of_all_words[0]\n","    word_list2 = zeroes_and_ones_of_all_words[1]\n","    if word == \"and\":\n","        bitwise_op = [w1 \u0026 w2 for (w1,w2) in zip(word_list1,word_list2)]\n","        zeroes_and_ones_of_all_words.remove(word_list1)\n","        zeroes_and_ones_of_all_words.remove(word_list2)\n","        zeroes_and_ones_of_all_words.insert(0, bitwise_op);\n","    elif word == \"or\":\n","        bitwise_op = [w1 | w2 for (w1,w2) in zip(word_list1,word_list2)]\n","        zeroes_and_ones_of_all_words.remove(word_list1)\n","        zeroes_and_ones_of_all_words.remove(word_list2)\n","        zeroes_and_ones_of_all_words.insert(0, bitwise_op);\n","    elif word == \"not\":\n","        bitwise_op = [not w1 for w1 in word_list2]\n","        bitwise_op = [int(b == True) for b in bitwise_op]\n","        zeroes_and_ones_of_all_words.remove(word_list2)\n","        zeroes_and_ones_of_all_words.remove(word_list1)\n","        bitwise_op = [w1 \u0026 w2 for (w1,w2) in zip(word_list1,bitwise_op)]\n","        zeroes_and_ones_of_all_words.insert(0, bitwise_op);\n","        \n","files = []    \n","print(zeroes_and_ones_of_all_words)\n","lis = zeroes_and_ones_of_all_words[0]\n","cnt = 1\n","for index in lis:\n","    if index == 1:\n","        files.append(files_with_index[cnt])\n","    cnt = cnt+1\n","    \n","print(files)"]},{"cell_type":"markdown","metadata":{"id":"qgp_NOpmdar1"},"source":["# **Question 3**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1643985879073,"user":{"displayName":"Anisha Kaushik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05661748900528311484"},"user_tz":-330},"id":"AdyFk8nKLhCT","outputId":"2027e9a4-0c01-4045-de20-3e4c1d3beed0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","Top words in document 1\n","\tWord: Systems, TF-IDF: 0.12771\n","\tWord: with, TF-IDF: 0.11454\n","\tWord: database, TF-IDF: 0.11454\n","Top words in document 2\n","\tWord: Storage, TF-IDF: 0.36652\n","\tWord: in, TF-IDF: 0.10217\n","\tWord: Information, TF-IDF: 0.04463\n","Top words in document 3\n","\tWord: Systems, TF-IDF: 0.10217\n","\tWord: Digital, TF-IDF: 0.09163\n","\tWord: can, TF-IDF: 0.09163\n","Top words in document 4\n","\tWord: Speech, TF-IDF: 0.10217\n","\tWord: Retrieval, TF-IDF: 0.10217\n","\tWord: Filtering, TF-IDF: 0.09163\n","Top words in document 5\n","\tWord: storage, TF-IDF: 0.22907\n","\tWord: Database, TF-IDF: 0.11454\n","\tWord: Management, TF-IDF: 0.11454\n"]}],"source":["import math\n","import nltk\n","nltk.download('punkt')\n","from textblob import TextBlob as tb\n","\n","def tf(word, blob):\n","    return blob.words.count(word) / len(blob.words)\n","\n","def n_containing(word, bloblist):\n","    return sum(1 for blob in bloblist if word in blob.words)\n","\n","def idf(word, bloblist):\n","    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n","\n","def tfidf(word, blob, bloblist):\n","    return tf(word, blob) * idf(word, bloblist)\n","\n","document1 = tb(\"\"\"Information Retrieval Systems is used with database systems\"\"\")\n","document2 = tb(\"\"\"Information is in Storage Storage\"\"\")\n","document3 = tb(\"\"\"Digital Speech systems can be used in Synthesis and Systems \"\"\")\n","document4 = tb(\"\"\"Speech Filtering, Speech Retrieval systems are applications of Information Retrieval \"\"\")\n","document5 = tb(\"\"\"Database Management system is used for storage storage\"\"\")\n","\n","bloblist = [document1, document2, document3, document4, document5]\n","for i, blob in enumerate(bloblist):\n","    print(\"Top words in document {}\".format(i + 1))\n","    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n","    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n","    for word, score in sorted_words[:3]:\n","        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"]},{"cell_type":"markdown","metadata":{"id":"gktNe9uHeLhS"},"source":["## **Question 4**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356,"status":"ok","timestamp":1643991876125,"user":{"displayName":"Anisha Kaushik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05661748900528311484"},"user_tz":-330},"id":"6vPZ8l5Mddym","outputId":"2a0f9448-f6e4-4195-ef26-5ea2ceee7aa8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cosine Similarity: \n","[[1.         0.23904572]\n"," [0.23904572 1.        ]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["# Define the documents\n","doc1 = \"Information Retrieval Systems is used with database systems\"\n","\n","doc2 = \"Information is in Storage Storage\"\n","\n","\n","documents = [doc1, doc2]\n","\n","# Scikit Learn\n","from sklearn.feature_extraction.text import CountVectorizer\n","import pandas as pd\n","\n","# Create the Document Term Matrix\n","count_vectorizer = CountVectorizer(stop_words='english')\n","count_vectorizer = CountVectorizer()\n","sparse_matrix = count_vectorizer.fit_transform(documents)\n","\n","# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n","doc_term_matrix = sparse_matrix.todense()\n","df = pd.DataFrame(doc_term_matrix, \n","                  columns=count_vectorizer.get_feature_names(), \n","                  index=['doc1', 'doc2'])\n","df\n","\n","# Compute Cosine Similarity\n","from sklearn.metrics.pairwise import cosine_similarity\n","print(\"Cosine Similarity: \")\n","print(cosine_similarity(df, df))"]},{"cell_type":"markdown","metadata":{"id":"9fAw-XTQe8sC"},"source":["# Question 5\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1643991788710,"user":{"displayName":"Anisha Kaushik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05661748900528311484"},"user_tz":-330},"id":"sY86urXke8Dq","outputId":"0118bea4-b49d-44d3-8bd4-ffd19b8b56a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dice Coefficient 0.41509433962264153\n"]}],"source":["def dice_coefficient(a, b):\n","    \"\"\"dice coefficient 2nt/(na + nb).\"\"\"\n","    if not len(a) or not len(b): return 0.0\n","    if len(a) == 1:  a=a+u'.'\n","    if len(b) == 1:  b=b+u'.'\n","    \n","    a_bigram_list=[]\n","    for i in range(len(a)-1):\n","      a_bigram_list.append(a[i:i+2])\n","    b_bigram_list=[]\n","    for i in range(len(b)-1):\n","      b_bigram_list.append(b[i:i+2])\n","      \n","    a_bigrams = set(a_bigram_list)\n","    b_bigrams = set(b_bigram_list)\n","    overlap = len(a_bigrams \u0026 b_bigrams)\n","    dice_coeff = overlap * 2.0/(len(a_bigrams) + len(b_bigrams))\n","    return dice_coeff\n","\n","doc3 = \"Digital Speech systems can be used in Synthesis and Systems\"\n","doc4 = \"Speech Filtering, Speech Retrieval systems are applications of Information Retrieval\"\n","result = dice_coefficient(doc3,doc4)\n","print(\"Dice Coefficient\",result)"]},{"cell_type":"markdown","metadata":{"id":"yicTee0DgOYe"},"source":["# **Question 6**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1643991718807,"user":{"displayName":"Anisha Kaushik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05661748900528311484"},"user_tz":-330},"id":"VqgaEcg8gN6g","outputId":"80658ad9-f9ea-476f-8bc2-abad6d880eef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Jaccard co-efficient: 0.125\n"]}],"source":["doc4 =\"Speech Filtering, Speech Retrieval systems are applications of Information Retrieval \"\n","doc5 =\"Digital Speech systems can be used in Synthesis and Systems\"\n","\n","def get_jaccard_sim(str1, str2): \n","    a = set(str1.split()) \n","    b = set(str2.split())\n","    c = a.intersection(b)\n","    return float(len(c)) / (len(a) + len(b) - len(c))\n","\n","result = get_jaccard_sim(doc4,doc5)\n","print(\"Jaccard co-efficient:\" ,result)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPdyc7YnFQhNI56NXgDYJU/","collapsed_sections":[],"name":"WebMining lab-4.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}