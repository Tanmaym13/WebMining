{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WebMining lab-3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOOsTyt8h3VjcYvN9KsRVJQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **QUESTION 1**"],"metadata":{"id":"wYLeIb3pfFqU"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75lxgUg5fEwi","executionInfo":{"status":"ok","timestamp":1643275409594,"user_tz":-330,"elapsed":384,"user":{"displayName":"Anisha Kaushik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05661748900528311484"}},"outputId":"2053580e-77ba-41cf-fcaf-b7851d38b417"},"outputs":[{"output_type":"stream","name":"stdout","text":["a : {'freq': 2, 'listing': [(1, 2), (3, 2)]}\n","and : {'freq': 1, 'listing': [(5, 2)]}\n","applications : {'freq': 2, 'listing': [(1, 8), (4, 7)]}\n","be : {'freq': 1, 'listing': [(4, 3)]}\n","beautiful : {'freq': 1, 'listing': [(2, 0)]}\n","can : {'freq': 1, 'listing': [(4, 2)]}\n","crawling : {'freq': 1, 'listing': [(5, 3)]}\n","for : {'freq': 4, 'listing': [(1, 5), (2, 4), (3, 5), (4, 5)]}\n","framework : {'freq': 1, 'listing': [(1, 4)]}\n","is : {'freq': 4, 'listing': [(1, 1), (2, 2), (3, 1), (5, 5)]}\n","it : {'freq': 1, 'listing': [(3, 0)]}\n","java : {'freq': 1, 'listing': [(4, 0)]}\n","package : {'freq': 1, 'listing': [(3, 4)]}\n","pages : {'freq': 1, 'listing': [(3, 8)]}\n","parsing : {'freq': 1, 'listing': [(3, 6)]}\n","portable : {'freq': 1, 'listing': [(1, 3)]}\n","programming : {'freq': 1, 'listing': [(4, 1)]}\n","python : {'freq': 1, 'listing': [(3, 3)]}\n","scraping : {'freq': 2, 'listing': [(2, 6), (5, 0)]}\n","selenium : {'freq': 1, 'listing': [(1, 0)]}\n","soup : {'freq': 1, 'listing': [(2, 1)]}\n","testing : {'freq': 1, 'listing': [(1, 6)]}\n","the : {'freq': 1, 'listing': [(3, 7)]}\n","used : {'freq': 1, 'listing': [(4, 4)]}\n","useful : {'freq': 2, 'listing': [(2, 3), (5, 6)]}\n","web : {'freq': 5, 'listing': [(1, 7), (2, 5), (4, 6), (5, 1), (5, 4)]}\n"]}],"source":["import re \n","documents =['doc1','doc2','doc3','doc4','doc5'] \n","index={}\n","for id,doc in enumerate(documents): \n","   filename = doc+\".txt\" \n","   with open(filename,'r') as fp: \n","    data = \"\".join(fp.readlines()) \n","    data = data.lower() \n","    ext_words = re.findall(r\"([a-z0-9-]+)\",data) \n","    for pos,word in enumerate(ext_words): \n","      if word[-1]=='s': \n","        if word[:-1] in index: \n","          word = word[:-1] \n","        elif word[:-2] in index: \n","          word = word[:-2] \n","\n","      if word not in index: \n","        index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n","      else: \n","        index[word]['freq']+=1 \n","        index[word]['listing'].append((id+1,pos)) \n","from collections import OrderedDict \n","index = OrderedDict(sorted(index.items())) \n","with open(\"inverted.txt\",'w') as fp: \n","  for key in index: \n","    print(f\"{key} : {index[key]}\") \n","    fp.write(f\"{key} : {index[key]}\\n\")"]},{"cell_type":"markdown","source":["## QUESTION 2\n","# Part - 1"],"metadata":{"id":"ivTUzIpXrNT4"}},{"cell_type":"code","source":["import re \n","documents =['doc1','doc2','doc3','doc4','doc5'] \n","index={}\n","for id,doc in enumerate(documents): \n","   filename = doc+\".txt\" \n","   with open(filename,'r') as fp: \n","    data = \"\".join(fp.readlines()) \n","    data = data.lower() \n","    #print(len(data))\n","    if re.findall(r\"\\bselenium\\b\", data) and re.findall(r\"\\bweb\\b\", data):\n","      print(\"Match found in\", filename)\n","      ext_words1 = re.findall(r\"\\bselenium\\b\", data) \n","      ext_words2 = re.findall(r\"\\bweb\\b\", data) \n","      for pos,word in enumerate(ext_words1): \n","        if word not in index: \n","          index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n","        else: \n","          index[word]['freq']+=1 \n","          index[word]['listing'].append((id+1,pos)) \n","      for pos,word in enumerate(ext_words2): \n","        if word not in index: \n","          index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n","        else: \n","          index[word]['freq']+=1 \n","          index[word]['listing'].append((id+1,pos)) \n","    else:\n","     print(\"No match found in\", filename) \n","print(\"\\n\")    \n","from collections import OrderedDict \n","index = OrderedDict(sorted(index.items())) \n","with open(\"inverted.txt\",'w') as fp:\n","  print(\"Answer: \\n\") \n","  for key in index: \n","    print(f\"{key} : {index[key]}\") \n","    fp.write(f\"{key} : {index[key]}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FEx0a9xrx36","executionInfo":{"status":"ok","timestamp":1643275164811,"user_tz":-330,"elapsed":394,"user":{"displayName":"Anisha Kaushik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05661748900528311484"}},"outputId":"ab521ea1-26c3-4859-a9c1-9f572e3cc2c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Match found in doc1.txt\n","No match found in doc2.txt\n","No match found in doc3.txt\n","No match found in doc4.txt\n","No match found in doc5.txt\n","\n","\n","Answer: \n","\n","selenium : {'freq': 1, 'listing': [(1, 0)]}\n","web : {'freq': 1, 'listing': [(1, 0)]}\n"]}]},{"cell_type":"markdown","source":["# **QUESTION 2**\n","# Part - 2"],"metadata":{"id":"Y9FI5RzBrNC4"}},{"cell_type":"code","source":["import re \n","documents =['doc1','doc2','doc3','doc4','doc5'] \n","index={}\n","for id,doc in enumerate(documents): \n","   filename = doc+\".txt\" \n","   with open(filename,'r') as fp: \n","    data = \"\".join(fp.readlines()) \n","    data = data.lower() \n","    #print(len(data))\n","    ext_words = re.findall(r\"\\bsoup\\b\", data)\n","    for pos,word in enumerate(ext_words): \n","      if word not in index: \n","        index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n","      else: \n","        index[word]['freq']+=1 \n","        index[word]['listing'].append((id+1,pos)) \n","from collections import OrderedDict \n","index = OrderedDict(sorted(index.items())) \n","with open(\"inverted.txt\",'w') as fp: \n","  for key in index: \n","    print(f\"{key} : {index[key]}\") \n","    fp.write(f\"{key} : {index[key]}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dDTaCOLAryxg","executionInfo":{"status":"ok","timestamp":1643275175886,"user_tz":-330,"elapsed":371,"user":{"displayName":"Anisha Kaushik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05661748900528311484"}},"outputId":"46b61780-7055-4e4d-f7a3-08f21322534b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["soup : {'freq': 1, 'listing': [(2, 0)]}\n"]}]},{"cell_type":"markdown","source":["# **QUESTION 2** \n","# Part - 3"],"metadata":{"id":"wM0nzKKpfKp5"}},{"cell_type":"code","source":["import re \n","documents =['doc1','doc2','doc3','doc4','doc5'] \n","index={}\n","for id,doc in enumerate(documents): \n","   filename = doc+\".txt\" \n","   with open(filename,'r') as fp: \n","    data = \"\".join(fp.readlines()) \n","    data = data.lower() \n","    #print(len(data))\n","    ext_words1 = re.compile(r\"\\bpython\\b | \\bjava\\b\",flags=re.I | re.X)\n","    ext_words2=ext_words1.findall(data)\n","    for pos,word in enumerate(ext_words2): \n","      if word not in index: \n","        index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n","      else: \n","        index[word]['freq']+=1 \n","        index[word]['listing'].append((id+1,pos)) \n","from collections import OrderedDict \n","index = OrderedDict(sorted(index.items())) \n","with open(\"inverted.txt\",'w') as fp: \n","  for key in index: \n","    print(f\"{key} : {index[key]}\") \n","    fp.write(f\"{key} : {index[key]}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jD3WJpg5fNuq","executionInfo":{"status":"ok","timestamp":1643275182909,"user_tz":-330,"elapsed":394,"user":{"displayName":"Anisha Kaushik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05661748900528311484"}},"outputId":"d02c214f-f381-43ba-de49-a23f65270310"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["java : {'freq': 1, 'listing': [(4, 0)]}\n","python : {'freq': 1, 'listing': [(3, 0)]}\n"]}]},{"cell_type":"markdown","source":["# **QUESTION 2**\n","# Part - 4"],"metadata":{"id":"ZwJhLIrrrmKM"}},{"cell_type":"code","source":["import re \n","documents =['doc1','doc2','doc3','doc4','doc5'] \n","index={}\n","for id,doc in enumerate(documents): \n","   filename = doc+\".txt\" \n","   with open(filename,'r') as fp: \n","    data = \"\".join(fp.readlines()) \n","    data = data.lower() \n","    #print(len(data))\n","    if re.findall(r\"\\bweb\\b\", data) and re.findall(r\"\\bcraw\\b\", data):\n","      print(\"Match found in\", filename)\n","      ext_words1 = re.findall(r\"\\bweb\\b\", data) \n","      ext_words2 = re.findall(r\"\\bcraw\\b\", data) \n","      for pos,word in enumerate(ext_words1): \n","        if word not in index: \n","          index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n","        else: \n","          index[word]['freq']+=1 \n","          index[word]['listing'].append((id+1,pos)) \n","      for pos,word in enumerate(ext_words2): \n","        if word not in index: \n","          index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n","        else: \n","          index[word]['freq']+=1 \n","          index[word]['listing'].append((id+1,pos)) \n","    else:\n","     print(\"No match found in\", filename) \n","     #break\n","print(\"\\n\")    \n","from collections import OrderedDict \n","index = OrderedDict(sorted(index.items())) \n","with open(\"inverted.txt\",'w') as fp:\n","  #print(\"Answer: \\n\") \n","  for key in index: \n","    print(f\"{key} : {index[key]}\") \n","    fp.write(f\"{key} : {index[key]}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLEdJat-rv9O","executionInfo":{"status":"ok","timestamp":1643275330133,"user_tz":-330,"elapsed":381,"user":{"displayName":"Anisha Kaushik","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05661748900528311484"}},"outputId":"7594f609-8b9c-45c7-9630-9c9b7e496799"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No match found in doc1.txt\n","No match found in doc2.txt\n","No match found in doc3.txt\n","No match found in doc4.txt\n","No match found in doc5.txt\n","\n","\n"]}]}]}